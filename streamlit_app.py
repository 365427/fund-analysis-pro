import streamlit as st
import pandas as pd
import os
import time
import requests
import akshare as ak
import inspect
import datetime
import io # ç”¨äºå¤„ç†ä¸Šä¼ çš„æ–‡ä»¶æµ

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="åŸºé‡‘æŒä»“åˆ†æ Pro (AkShare+DeepSeek)", layout="wide")
st.title("ğŸ“ˆ åŸºé‡‘æŒä»“å®æ—¶æ·±åº¦åˆ†æ")

# --- 2. è¾…åŠ©å‡½æ•°ï¼šåˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ ---
def is_trading_day(date_to_check):
    if date_to_check.weekday() > 4:
        return False
    return True

# --- 3. æ ¸å¿ƒæŠ“å–å‡½æ•° ---
@st.cache_data(ttl=3600)
def get_detail_data(fund_code):
    try:
        df = ak.fund_portfolio_hold_em(symbol=fund_code)
        if df.empty:
            return None, "æœªæ‰¾åˆ°æŒä»“æ•°æ®", None
        date_cols = [col for col in df.columns if 'æ—¶é—´' in col or 'æ—¥æœŸ' in col or 'quarter' in col.lower() or 'date' in col.lower()]
        if not date_cols:
            latest_df = df.copy()
            report_date = "æœ€æ–°ä¸€æœŸ"
        else:
            date_col = date_cols[0]
            latest_date = df[date_col].max()
            latest_df = df[df[date_col] == latest_date].copy()
            report_date = str(latest_date)
        required_cols = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'å å‡€å€¼æ¯”ä¾‹']
        if not all(col in latest_df.columns for col in required_cols):
            missing = [col for col in required_cols if col not in latest_df.columns]
            return None, f"æ•°æ®æ ¼å¼ä¸åŒ¹é…ï¼Œç¼ºå°‘å­—æ®µ: {missing}", None
        latest_df = latest_df[required_cols].copy()
        latest_df.rename(columns={'å å‡€å€¼æ¯”ä¾‹': 'curr_weight'}, inplace=True)
        latest_df['curr_weight'] = pd.to_numeric(latest_df['curr_weight'], errors='coerce').fillna(0)
        return latest_df, report_date, None
    except Exception as e:
        error_msg = f"AkShare è·å–å¤±è´¥: {str(e)}"
        return None, error_msg, None

# --- 4. è·å–å®æ—¶å‡€å€¼ä¼°ç®—æˆ–å†å²æ¶¨è·Œå¹… ---
def get_fund_realtime_info(fund_code, is_today_trading_day):
    try:
        sig = inspect.signature(ak.fund_open_fund_info_em)
        params = list(sig.parameters.keys())
        fund_param_name = None
        for name in ['symbol', 'code', 'fund_code', 'fund']:
            if name in params:
                fund_param_name = name
                break
        if not fund_param_name:
            print(f"DEBUG: æœªæ‰¾åˆ°åŸºé‡‘ä»£ç å¯¹åº”çš„å‚æ•°åã€‚å¯ç”¨å‚æ•°: {params}")
            return "N/A", "N/A"
        call_kwargs = {fund_param_name: fund_code, 'indicator': 'å•ä½å‡€å€¼èµ°åŠ¿'}
        hist_df = ak.fund_open_fund_info_em(**call_kwargs)
        if hist_df.empty:
            print(f"DEBUG: åŸºé‡‘ {fund_code} çš„å†å²æ•°æ®ä¸ºç©ºã€‚")
            return "N/A", "N/A"
        date_col_candidates = [col for col in hist_df.columns if 'å‡€å€¼æ—¥æœŸ' in col or 'date' in col.lower() or 'æ—¥æœŸ' in col]
        if not date_col_candidates:
            print(f"DEBUG: åŸºé‡‘ {fund_code} æœªæ‰¾åˆ°æ—¥æœŸåˆ—ã€‚åˆ—åä¸º: {list(hist_df.columns)}")
            return "N/A", "N/A"
        date_col = date_col_candidates[0]
        nav_col_candidates = [col for col in hist_df.columns if 'å•ä½å‡€å€¼' in col or 'ä¼°ç®—' in col]
        if not nav_col_candidates:
             print(f"DEBUG: åŸºé‡‘ {fund_code} æœªæ‰¾åˆ°å‡€å€¼åˆ—ã€‚åˆ—åä¸º: {list(hist_df.columns)}")
             return "N/A", "N/A"
        nav_col = nav_col_candidates[0]
        hist_df.sort_values(by=date_col, ascending=False, inplace=True)
        hist_df.reset_index(drop=True, inplace=True)
        nav_series = hist_df[nav_col].dropna()
        if len(nav_series) < 2:
            print(f"DEBUG: åŸºé‡‘ {fund_code} æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æ¶¨è·Œå¹…ã€‚")
            return "N/A", "N/A"
        current_nav = nav_series.iloc[0]
        prev_nav = nav_series.iloc[1]
        if prev_nav == 0:
            daily_growth = 0
        else:
            daily_growth = ((current_nav - prev_nav) / prev_nav) * 100
        formatted_nav = f"{current_nav:.4f}"
        formatted_growth = f"{daily_growth:+.2f}%"
        return formatted_nav, formatted_growth
    except KeyError as e:
        print(f"DEBUG: åŸºé‡‘ {fund_code} å‘ç”Ÿ KeyError: {e}.")
        return "N/A", "N/A"
    except IndexError as e:
        print(f"DEBUG: åŸºé‡‘ {fund_code} å‘ç”Ÿ IndexError: {e}.")
        return "N/A", "N/A"
    except Exception as e:
        print(f"DEBUG: åŸºé‡‘ {fund_code} å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return "N/A", "N/A"

# --- 5. DeepSeek å…œåº• ---
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
def call_deepseek_for_fund_info(fund_code, fund_name):
    if not DEEPSEEK_API_KEY:
        return "æœªé…ç½®æˆ–æ— æ•ˆçš„ DeepSeek API Keyï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®ã€‚"
    try:
        url = "https://api.deepseek.com/v1/chat/completions"
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {DEEPSEEK_API_KEY}"}
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ•°æ®åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„åŸºé‡‘åç§°å’Œä»£ç ï¼Œç®€è¦è¯´æ˜è¯¥åŸºé‡‘çš„æœ€æ–°æŒä»“æ¦‚å†µï¼ˆå¦‚ä¸»è¦è¡Œä¸šã€é‡ä»“è‚¡ç­‰ï¼‰ã€‚å›ç­”è¯·ç®€æ´ã€ä¸“ä¸šï¼Œä¸è¶…è¿‡100å­—ã€‚"},
                {"role": "user", "content": f"åŸºé‡‘åç§°ï¼š{fund_name}ï¼ŒåŸºé‡‘ä»£ç ï¼š{fund_code}ã€‚è¯·æä¾›å…¶æœ€æ–°æŒä»“æ¦‚å†µã€‚"}
            ],
            "temperature": 0.3,
            "max_tokens": 200
        }
        response = requests.post(url, headers=headers, json=payload, timeout=15)
        if response.status_code == 401:
            return "API è®¤è¯å¤±è´¥ (401)ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ API Key æ˜¯å¦æ­£ç¡®æœ‰æ•ˆã€‚"
        elif response.status_code == 429:
            return "è¯·æ±‚è¿‡äºé¢‘ç¹æˆ–è¶…å‡ºé…é¢ (429)ã€‚"
        elif response.status_code != 200:
            return f"DeepSeek è°ƒç”¨å¤±è´¥: {response.status_code}, {response.text}"
        response_json = response.json()
        if 'choices' in response_json and len(response_json['choices']) > 0:
            return response_json['choices'][0]['message']['content'].strip()
        else:
            return f"API è¿”å›äº†æ„å¤–çš„å“åº”æ ¼å¼: {response_json}"
    except requests.exceptions.Timeout:
        return "è°ƒç”¨ DeepSeek æ—¶è¯·æ±‚è¶…æ—¶ã€‚"
    except requests.exceptions.RequestException as e:
        return f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}"
    except Exception as e:
        return f"è°ƒç”¨ DeepSeek å‡ºé”™: {str(e)}"

# --- 6. æœç´¢ä¸æ”¶è—é€»è¾‘ ---
@st.cache_data(ttl=3600)
def get_all_funds():
    try:
        return ak.fund_name_em()[['åŸºé‡‘ä»£ç ', 'åŸºé‡‘ç®€ç§°']]
    except Exception as e:
        st.warning(f"æ— æ³•è·å–åŸºé‡‘åˆ—è¡¨: {e}")
        return pd.DataFrame(columns=['åŸºé‡‘ä»£ç ', 'åŸºé‡‘ç®€ç§°'])

CSV_FILE = 'fund_favs.csv'

def load_favs(): 
    if os.path.exists(CSV_FILE):
        df = pd.read_csv(CSV_FILE, dtype={'ä»£ç ': str})
        if 'æ¶¨è·Œå¹…' not in df.columns:
            df['æ¶¨è·Œå¹…'] = 'N/A'
        return df[['ä»£ç ', 'åç§°', 'æ¶¨è·Œå¹…']]
    else:
        return pd.DataFrame(columns=['ä»£ç ', 'åç§°', 'æ¶¨è·Œå¹…'])

def save_favs(df): 
    df.to_csv(CSV_FILE, index=False)

# --- 7. äº‘ç«¯å¤‡ä»½ä¸æ¢å¤åŠŸèƒ½ (Gist) ---
GIST_TOKEN = os.getenv('GITHUB_GIST_TOKEN')
GIST_ID = os.getenv('FUND_FAVS_GIST_ID')

def backup_to_gist():
    if not GIST_TOKEN or not GIST_ID:
        return "âŒ å¤±è´¥: æœªè®¾ç½® GITHUB_GIST_TOKEN æˆ– FUND_FAVS_GIST_ID ç¯å¢ƒå˜é‡ã€‚"
    try:
        if not os.path.exists(CSV_FILE):
            return "âš ï¸ è­¦å‘Š: æœ¬åœ°æ”¶è—åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•å¤‡ä»½ã€‚"
        with open(CSV_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
        url = f"https://api.github.com/gists/{GIST_ID}"
        headers = {
            "Authorization": f"token {GIST_TOKEN}",
            "Accept": "application/vnd.github.v3+json"
        }
        data = {
            "files": {
                "fund_favs.csv": {
                    "content": content
                }
            }
        }
        response = requests.patch(url, headers=headers, json=data)
        if response.status_code == 200:
            return "âœ… æˆåŠŸ: æ•°æ®å·²å¤‡ä»½åˆ°äº‘ç«¯ Gistã€‚"
        else:
            return f"âŒ å¤±è´¥: Gist API å“åº”é”™è¯¯ {response.status_code}: {response.text}"
    except Exception as e:
        return f"âŒ å¤±è´¥: å¤‡ä»½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

def restore_from_gist():
    if not GIST_TOKEN or not GIST_ID:
        return "âŒ å¤±è´¥: æœªè®¾ç½® GITHUB_GIST_TOKEN æˆ– FUND_FAVS_GIST_ID ç¯å¢ƒå˜é‡ã€‚"
    try:
        url = f"https://api.github.com/gists/{GIST_ID}"
        headers = {
            "Authorization": f"token {GIST_TOKEN}",
            "Accept": "application/vnd.github.v3+json"
        }
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            gist_data = response.json()
            file_content = gist_data['files'].get('fund_favs.csv', {}).get('content', '')
            if not file_content:
                return "âŒ å¤±è´¥: Gist ä¸­æœªæ‰¾åˆ° fund_favs.csv æ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©ºã€‚"
            with open(CSV_FILE, 'w', encoding='utf-8') as f:
                f.write(file_content)
            st.rerun()
            return "âœ… æˆåŠŸ: æ•°æ®å·²ä»äº‘ç«¯ Gist æ¢å¤ã€‚é¡µé¢å·²åˆ·æ–°ã€‚"
        else:
            return f"âŒ å¤±è´¥: Gist API å“åº”é”™è¯¯ {response.status_code}: {response.text}"
    except Exception as e:
        return f"âŒ å¤±è´¥: æ¢å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

# --- 8. æœ¬åœ°æ–‡ä»¶å¯¼å…¥åŠŸèƒ½ ---
def restore_from_local_file(uploaded_file):
    try:
        # ä½¿ç”¨ pandas è¯»å–ä¸Šä¼ çš„ CSV æ–‡ä»¶
        # æ³¨æ„ï¼šuploaded_file æ˜¯ä¸€ä¸ª BytesIO å¯¹è±¡
        uploaded_df = pd.read_csv(uploaded_file, dtype={'ä»£ç ': str})

        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = {'ä»£ç ', 'åç§°', 'æ¶¨è·Œå¹…'}
        if not required_columns.issubset(uploaded_df.columns.tolist()):
            missing_cols = required_columns - set(uploaded_df.columns.tolist())
            return f"âŒ å¤±è´¥: ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}"

        # ä¸ç°æœ‰æ•°æ®åˆå¹¶ï¼Œå»é‡
        current_df = load_favs()
        combined_df = pd.concat([current_df, uploaded_df], ignore_index=True)
        unique_df = combined_df.drop_duplicates(subset=['ä»£ç '], keep='last')

        # ä¿å­˜åˆå¹¶åçš„æ•°æ®
        save_favs(unique_df)

        # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ–°æ•°æ®
        st.rerun()
        return "âœ… æˆåŠŸ: æ•°æ®å·²ä»æœ¬åœ°æ–‡ä»¶å¯¼å…¥ã€‚é¡µé¢å·²åˆ·æ–°ã€‚"

    except pd.errors.EmptyDataError:
        return "âŒ å¤±è´¥: ä¸Šä¼ çš„æ–‡ä»¶æ˜¯ç©ºçš„ã€‚"
    except Exception as e:
        return f"âŒ å¤±è´¥: è§£æä¸Šä¼ æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"


# --- 9. ä¾§è¾¹æ äº¤äº’ ---
st.sidebar.header("â­ åŸºé‡‘æœç´¢")
all_funds = get_all_funds()
fav_df = load_favs()

search = st.sidebar.text_input("ğŸ” è¾“å…¥åç§°æˆ–ä»£ç  (å¦‚: 161725)")
f_code, f_name = "", ""
if search:
    res = all_funds[(all_funds['åŸºé‡‘ä»£ç '].str.contains(search)) | (all_funds['åŸºé‡‘ç®€ç§°'].str.contains(search))]
    if not res.empty:
        f_code, f_name = res.iloc[0]['åŸºé‡‘ä»£ç '], res.iloc[0]['åŸºé‡‘ç®€ç§°']
        st.sidebar.success(f"å·²é€‰: {f_name}")

# --- 10. äº‘ç«¯ & æœ¬åœ°å¤‡ä»½å¯¼å…¥æŒ‰é’® (æ”¾åœ¨ä¾§è¾¹æ ) ---
st.sidebar.header("â˜ï¸ æ•°æ®åŒæ­¥")
backup_col, restore_col = st.sidebar.columns(2)
with backup_col:
    if st.button("ğŸ“¤ äº‘ç«¯å¤‡ä»½"):
        message = backup_to_gist()
        st.sidebar.info(message)
with restore_col:
    if st.button("ğŸ“¥ äº‘ç«¯å¯¼å…¥"):
        message = restore_from_gist()
        st.sidebar.info(message)

st.sidebar.header("ğŸ“± æœ¬åœ°å¯¼å…¥")
uploaded_file = st.sidebar.file_uploader(
    "é€‰æ‹©æœ¬åœ°CSVæ–‡ä»¶ (fund_favs.csv)",
    type=["csv"],
    accept_multiple_files=False,
    key="local_upload_widget"
)

if uploaded_file is not None:
    message = restore_from_local_file(uploaded_file)
    st.sidebar.info(message)
    # æ¸…ç©ºä¸Šä¼ ç»„ä»¶çš„çŠ¶æ€ï¼Œé˜²æ­¢é‡å¤å¤„ç†
    # è¿™å¯ä»¥é€šè¿‡é‡æ–°æ¸²æŸ“é¡µé¢æ¥é—´æ¥å®ç°ï¼Œæˆ–è€…ä½¿ç”¨ session_state æ§åˆ¶
    # è¿™é‡Œæˆ‘ä»¬ç›´æ¥åœ¨å¤„ç†å®Œåæ˜¾ç¤ºæ¶ˆæ¯ï¼Œå®é™…çš„æ¸…ç©ºå‘ç”Ÿåœ¨é¡µé¢åˆ·æ–°å

# --- 11. ä¸»ç•Œé¢ï¼šæ˜¾ç¤ºæ”¶è—åˆ—è¡¨ ---
st.subheader("æˆ‘çš„è‡ªé€‰åŸºé‡‘åˆ—è¡¨")
today = datetime.date.today()
is_today_a_trading_day = is_trading_day(today)

if not fav_df.empty:
    display_df = fav_df.copy()
    for i, row in display_df.iterrows():
        code = row['ä»£ç ']
        _, growth = get_fund_realtime_info(code, is_today_a_trading_day)
        display_df.loc[i, 'æ¶¨è·Œå¹…'] = growth
    
    # ğŸ”§ æ·»åŠ æ ·å¼ï¼šçº¢æ¶¨ç»¿è·Œ
    def color_growth(val):
        if pd.isna(val) or val == 'N/A':
            return 'color: gray;'
        elif isinstance(val, str) and val.startswith('+'):
            return 'color: red;'
        elif isinstance(val, str) and val.startswith('-'):
            return 'color: green;'
        else:
            # é’ˆå¯¹æ•°å€¼å‹æ¶¨è·Œå¹…ï¼ˆè™½ç„¶ç›®å‰æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼‰
            if val > 0:
                return 'color: red;'
            elif val < 0:
                return 'color: green;'
            else:
                return 'color: gray;'

    styled_df = display_df.style.applymap(color_growth, subset=['æ¶¨è·Œå¹…'])
    st.dataframe(styled_df, width='stretch')
    status_text = "ğŸ“Š **å½“å‰ä¸ºäº¤æ˜“æ—¥ï¼Œæ˜¾ç¤ºå®æ—¶ä¼°ç®—æ¶¨è·Œå¹…**" if is_today_a_trading_day else "ğŸ“Š **å½“å‰ä¸ºéäº¤æ˜“æ—¥ï¼Œæ˜¾ç¤ºä¸Šä¸€äº¤æ˜“æ—¥æ”¶ç›˜æ¶¨è·Œå¹…**"
    st.caption(status_text)
else:
    st.info("æ‚¨çš„è‡ªé€‰åŸºé‡‘åˆ—è¡¨ä¸ºç©ºã€‚è¯·åœ¨å·¦ä¾§æœç´¢å¹¶æ·»åŠ åŸºé‡‘ã€‚")

# --- 12. æŸ¥è¯¢å•ä¸ªåŸºé‡‘è¯¦æƒ… ---
if f_code:
    st.divider()
    st.subheader(f"ğŸ” å•ç‹¬åˆ†æ: {f_name} ({f_code})")
    current_nav, daily_growth = get_fund_realtime_info(f_code, is_today_a_trading_day)
    if daily_growth != "N/A":
        # ä¸ºå•ç‹¬æŸ¥è¯¢çš„æ¶¨è·Œå¹…ä¹Ÿåº”ç”¨çº¢æ¶¨ç»¿è·Œæ ·å¼ (é€šè¿‡ delta_color)
        # delta_color='inverse' ä¼šè®©æ­£å€¼æ˜¾ç¤ºä¸ºç»¿è‰²ï¼Œè´Ÿå€¼æ˜¾ç¤ºä¸ºçº¢è‰²ï¼Œä¸æ ‡å‡†ç›¸å
        # æˆ‘ä»¬éœ€è¦åå‘é€»è¾‘ï¼Œæ‰€ä»¥å¯¹äºæ­£å€¼(ä¸Šæ¶¨)ç”¨'reverse'è®©å®ƒå˜çº¢ï¼Œå¯¹äºè´Ÿå€¼(ä¸‹è·Œ)ç”¨'normal'è®©å®ƒå˜ç»¿
        # æˆ–è€…ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨ st.markdown æ¥æ˜¾ç¤ºå¸¦é¢œè‰²çš„æ–‡æœ¬ï¼Œæ›´çµæ´»
        # ä¸ºäº†ä¿æŒ st.metric çš„ç»“æ„ï¼Œæˆ‘ä»¬æš‚æ—¶åªç”¨ label æ˜¾ç¤ºé¢œè‰²ï¼Œvalue ä¸ç”¨ delta
        growth_delta_color = "inverse" if daily_growth.startswith('+') else "normal"
        st.metric(label="å®æ—¶ä¼°ç®—æ¶¨è·Œå¹…", value=daily_growth, delta=None, delta_color=growth_delta_color)
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("â• åŠ å…¥è‡ªé€‰"):
            new_entry = pd.DataFrame([{'ä»£ç ': f_code, 'åç§°': f_name, 'æ¶¨è·Œå¹…': daily_growth}])
            updated_fav_df = pd.concat([fav_df, new_entry], ignore_index=True).drop_duplicates(subset=['ä»£ç '], keep='first')
            save_favs(updated_fav_df)
            st.rerun()
    with col2:
        if st.button("â– ç§»å‡ºè‡ªé€‰"):
            updated_fav_df = fav_df[fav_df['ä»£ç '] != f_code].reset_index(drop=True)
            save_favs(updated_fav_df)
            st.rerun()
    
    h, msg_or_date, _ = get_detail_data(f_code)
    if h is not None:
        st.caption(f"ğŸ“… æŒä»“å­£åº¦: {msg_or_date}")
        display_data = []
        for _, r in h.iterrows():
            display_data.append({
                "è‚¡ç¥¨": f"{r['è‚¡ç¥¨åç§°']} ({r['è‚¡ç¥¨ä»£ç ']})",
                "ä»“ä½": f"{r['curr_weight']:.2f}%",
                "å˜åŠ¨": "-" 
            })
        st.dataframe(pd.DataFrame(display_data), width='stretch')
    else:
        st.error(msg_or_date)
        with st.spinner("æ­£åœ¨è°ƒç”¨ DeepSeek è·å–åŸºé‡‘ä¿¡æ¯..."):
            deepseek_response = call_deepseek_for_fund_info(f_code, f_name or "æœªçŸ¥åŸºé‡‘")
        st.info("ğŸ’¡ DeepSeek æä¾›çš„ä¿¡æ¯ï¼š")
        st.write(deepseek_response)
else:
    st.info("ğŸ’¡ è¯·åœ¨å·¦ä¾§è¾“å…¥ä½ æƒ³æŸ¥è¯¢çš„åŸºé‡‘åç§°æˆ–ä»£ç ")

# --- 13. éƒ¨ç½²æç¤º ---
st.sidebar.divider()
st.sidebar.markdown("**ğŸ“± æ‰‹æœºéƒ¨ç½²æç¤º:**")
st.sidebar.markdown("- åœ¨æ‰‹æœºæµè§ˆå™¨ä¸­æ‰“å¼€æ­¤åº”ç”¨ã€‚")
st.sidebar.markdown("- ä½¿ç”¨ä¾§è¾¹æ çš„å¤‡ä»½/å¯¼å…¥åŠŸèƒ½åŒæ­¥æ•°æ®ã€‚")
st.sidebar.markdown("- **æ‰‹æœºæœ¬åœ°å¯¼å…¥**: ç‚¹å‡»â€œé€‰æ‹©æœ¬åœ°CSVæ–‡ä»¶â€æŒ‰é’®ï¼Œä»æ‰‹æœºç›¸å†Œã€æ–‡ä»¶ç®¡ç†å™¨æˆ–å¾®ä¿¡ç­‰æ¸ é“é€‰æ‹© `fund_favs.csv` æ–‡ä»¶å¯¼å…¥ã€‚")
st.sidebar.markdown("- **é¦–æ¬¡éƒ¨ç½²å‰è¯·è®¾ç½®ç¯å¢ƒå˜é‡ã€‚**")

